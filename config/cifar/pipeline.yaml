#@ load("@ytt:data", "data")
---
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  name: ml-image-processing-pipeline-gprun-training
spec:
  entrypoint: train
  volumes:
    - name: secret-vol
      secret:
        secretName: greenplum-training-secret
  templates:
    - name: train
      steps:
        - - name: deploy-training-code
            template: deploy-code
            arguments:
              parameters:
                - name: user
                  value: #@ data.values.greenplum_user
                - name: host
                  value: #@ data.values.greenplum_master
                - name: shared_path
                  value: #@ data.values.greenplum_shared_path
                - name: pem_file
                  value: #@ data.values.greenplum_shared_path + "/creds/greenplum_pem"
                - name: shell_script
                  value: #@ data.values.training_shell_script
                - name: db_script
                  value: #@ data.values.training_db_script
                - name: db_schema
                  value: #@ data.values.greenplum_db_schema
        - - name: deploy-training-db
            template: deploy-db
            arguments:
              parameters:
                - name: user
                  value: #@ data.values.greenplum_user
                - name: host
                  value: #@ data.values.greenplum_master
                - name: db_name
                  value: #@ data.values.greenplum_training_db_name
                - name: db_script
                  value: #@ data.values.training_db_script
                - name: external_secret_ref
                  value: #@ data.values.greenplum_external_secret_ref
                - name: external_secret_ref_key
                  value: #@ data.values.greenplum_external_secret_ref_key
        - - name: upload-dataset
            template: run-training
            arguments:
              parameters:
                - name: mlflow_entry
                  value: "upload_dataset"
        - - name: train-model
            template: run-training
            arguments:
              parameters:
                - name: mlflow_entry
                  value: "train_model"
        - - name: evaluate-model
            template: run-training
            arguments:
              parameters:
                - name: mlflow_entry
                  value: "evaluate_model"
        - - name: promote-model-to-staging
            template: run-training
            arguments:
              parameters:
                - name: mlflow_entry
                  value: "promote_model_to_staging"
        - - name: deploy-inference-code
            template: deploy-code
            arguments:
              parameters:
                - name: user
                  value: #@ data.values.postgres_user
                - name: host
                  value: #@ data.values.postgres_host
                - name: shared_path
                  value: #@ data.values.postgres_shared_path
                - name: pem_file
                  value: #@ data.values.greenplum_shared_path + "/creds/greenplum_pem"
                - name: shell_script
                  value: #@ data.values.inference_shell_script
                - name: db_script
                  value: #@ data.values.inference_db_script
                - name: db_schema
                  value: #@ data.values.inference_db_schema
        - - name: deploy-inference-db
            template: deploy-db
            arguments:
              parameters:
                - name: user
                  value: #@ data.values.postgres_user
                - name: host
                  value: #@ data.values.postgres_host
                - name: db_name
                  value: #@ data.values.postgres_inference_db_name
                - name: db_script
                  value: #@ data.values.inference_db_script
                - name: external_secret_ref
                  value: #@ data.values.postgres_external_secret_ref
                - name: external_secret_ref_key
                  value: #@ data.values.postgres_external_secret_ref_key
    - name: deploy-code
      inputs:
        artifacts:
          - name: deploy-code-source
            path: "/usr/local"
            git:
              repo: #@ data.values.git_repo
              singleBranch: true
              branch: #@ data.values.environment_name
        parameters:
          - name: user
          - name: host
          - name: shared_path
          - name: pem_file
          - name: shell_script
          - name: db_script
          - name: db_schema
          - name: git_repo
            value: #@ data.values.git_repo
          - name: mlpipeline_git_repo
            value: #@ data.values.mlpipeline_git_repo
          - name: pyfunction_vendored_dependencies_uri
            value: #@ data.values.pyfunction_vendored_dependencies_uri
          - name: inference_namespace
            value: #@ data.values.postgres_inference_namespace
      script:
        image: busybox
        volumeMounts:
          - name: secret-vol
            mountPath: "{{inputs.parameters.shared_path}}/creds"
        workingDir: "/usr/local"
        command: [bash]
        source: |
          SCP_PEM_PATH="{{inputs.parameters.pem_file}}" \
          USER="{{inputs.parameters.user}}" \
          HOST="{{inputs.parameters.host}}" \
          SHARED_PATH="{{inputs.parameters.shared_path}}" \
          GIT_REPO="{{inputs.parameters.git_repo}}" \
          MLPIPELINE_GIT_REPO="{{inputs.parameters.mlpipeline_git_repo}}" \
          PYFUNC_VENDOR_URI="{{inputs.parameters.pyfunction_vendored_dependencies_uri}}" \
          NAMESPACE="{{inputs.parameters.inference_namespace}}" \
          DB_SCRIPT="{{inputs.parameters.db_script}}" \
          DB_SCHEMA="{{inputs.parameters.db_schema}}" \
          "{{inputs.parameters.shell_script}}"
    - name: deploy-db
      inputs:
        artifacts:
          - name: deploy-code-source
            path: "/liquibase"
            git:
              repo: #@ data.values.git_repo
              singleBranch: true
              branch: #@ data.values.environment_name
        parameters:
          - name: user
          - name: host
          - name: db_name
          - name: db_script
          - name: external_secret_ref
          - name: external_secret_ref_key
      script:
        image: liquibase/liquibase
        env:
          - name: HOST_PASSWORD
            valueFrom:
              secretKeyRef:
                name: "{{inputs.parameters.external_secret_ref}}"
                key: "{{inputs.parameters.external_secret_ref_key}}"
        command: [bash]
        source: |
          --changelog-file="/liquibase/{{inputs.parameters.db_script}}" \
          --url="jdbc:postgresql://{{inputs.parameters.host}}:5432/{{inputs.parameters.db_name}}?sslmode=require" \
          --username="{{inputs.parameters.user}}" \
          --password="${HOST_PASSWORD}" \
    - name: run-training
      inputs:
        parameters:
          - name: mlflow_entry
          - name: mlflow_stage
            value: #@ data.values.model_stage
          - name: git_repo
            value: #@ data.values.git_repo
          - name: experiment_name
            value: #@ data.values.experiment_name
          - name: environment_name
            value: #@ data.values.environment_name
          - name: user
            value: #@ data.values.greenplum_user
          - name: host
            value: #@ data.values.greenplum_master
          - name: db_name
            value: #@ data.values.greenplum_training_db_name
          - name: mlflow_tracking_uri
            value: #@ data.values.mlflow_tracking_uri
          - name: shared_path
            value: #@ data.values.greenplum_shared_path
      script:
        image: postgres
        env:
          - name: GREENPLUM_TRAINING_MASTER_PASSWORD
            valueFrom:
              secretKeyRef:
                name: greenplum-training-secret
                key: greenplum_master_password
        command: [psql]
        source: |
          postgresql://"{{inputs.parameters.user}}":${GREENPLUM_TRAINING_MASTER_PASSWORD}@"{{inputs.parameters.host}}":5432/"{{inputs.parameters.db_name}}"?sslmode=require -c
          'SELECT run_training_task("{{inputs.parameters.mlflow_stage}}",
                "{{inputs.parameters.git_repo}}",
                "{{inputs.parameters.mlflow_stage}}",
                "{{inputs.parameters.experiment_name}}",
                "{{inputs.parameters.environment_name}}",
                "{{inputs.parameters.mlflow_tracking_uri}}",
                "{{inputs.parameters.shared_path}}/mlapp";'